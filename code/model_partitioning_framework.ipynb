{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Comment these commands if you are running this notebook locally and your environment is already setted up\n",
    "!pip3 install -i https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/ onnxruntime-gpu==1.17.0\n",
    "!pip3 install ultralytics\n",
    "!pip3 install ortools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Loading and IR conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:07:17.060451Z",
     "iopub.status.busy": "2025-06-30T19:07:17.059970Z",
     "iopub.status.idle": "2025-06-30T19:07:23.062680Z",
     "shell.execute_reply": "2025-06-30T19:07:23.061337Z",
     "shell.execute_reply.started": "2025-06-30T19:07:17.060416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import onnx\n",
    "\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Print the detailed summary\n",
    "print(model.model)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "model.export(format=\"onnx\")  # creates 'yolo11n.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:07:32.021196Z",
     "iopub.status.busy": "2025-06-30T19:07:32.020623Z",
     "iopub.status.idle": "2025-06-30T19:07:32.105605Z",
     "shell.execute_reply": "2025-06-30T19:07:32.104178Z",
     "shell.execute_reply.started": "2025-06-30T19:07:32.021166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "model = onnx.load(\"yolo11n.onnx\")\n",
    "\n",
    "# Check the model's structure and ensure it's well-formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human-readable representation of the model\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:07:42.452217Z",
     "iopub.status.busy": "2025-06-30T19:07:42.451804Z",
     "iopub.status.idle": "2025-06-30T19:07:42.459149Z",
     "shell.execute_reply": "2025-06-30T19:07:42.458147Z",
     "shell.execute_reply.started": "2025-06-30T19:07:42.452191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nodes = 0\n",
    "\n",
    "for node in model.graph.node:\n",
    "    nodes += 1\n",
    "\n",
    "print(\"Number of nodes: \", nodes)\n",
    "\n",
    "operation_types = set(node.op_type for node in model.graph.node)\n",
    "\n",
    "print(\"\\nOperations: \\n\")\n",
    "print(\"\\n\".join(operation_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Device and Performance Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:07:50.172359Z",
     "iopub.status.busy": "2025-06-30T19:07:50.172006Z",
     "iopub.status.idle": "2025-06-30T19:07:50.185201Z",
     "shell.execute_reply": "2025-06-30T19:07:50.184115Z",
     "shell.execute_reply.started": "2025-06-30T19:07:50.172335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEVICE_PROFILE = {\n",
    "    \"nvidia_L40s\": {\n",
    "        \"gflops\": 91600,             # Peak GFLOPS from datasheet\n",
    "        \"tdp\": 350,                  # TDP in Watts\n",
    "        \"efficiency\": 91600 / 350,   # GFLOPS per Watt\n",
    "        \"static_power\": 350 * 0.1,   # Watts per hour\n",
    "        \"pcie_bandwidth\": 32,        # GB/s\n",
    "        \"memory_bandwidth\": 864      # GB/s\n",
    "    },\n",
    "    \"nvidia_tesla_T4\": {\n",
    "        \"gflops\": 8100,              # Peak GFLOPS from datasheet\n",
    "        \"tdp\": 70,                   # TDP in Watts\n",
    "        \"efficiency\": 8100 / 70,     # GFLOPS per Watt\n",
    "        \"static_power\": 70 * 0.1,    # Watts per hour\n",
    "        \"pcie_bandwidth\": 16,        # GB/s\n",
    "        \"memory_bandwidth\": 300      # GB/s\n",
    "    },\n",
    "    \"nvidia_A30\": {\n",
    "        \"gflops\": 10300,             # Peak GFLOPS from datasheet\n",
    "        \"tdp\": 165,                  # TDP in Watts\n",
    "        \"efficiency\": 10300 / 165,   # GFLOPS per Watt\n",
    "        \"static_power\": 165 * 0.1,   # Watts per hour\n",
    "        \"pcie_bandwidth\": 32,        # GB/s\n",
    "        \"memory_bandwidth\": 933      # GB/s\n",
    "    },\n",
    "    \"alveo_U55C_2_DPU\": {\n",
    "        \"gflops\": (8 / 4) * 1000,               # Peak GFLOPS from datasheet\n",
    "        \"tdp\": 115,                             # TDP in Watts\n",
    "        \"efficiency\": ((8 / 4) * 1000) / 115,   # GFLOPS per Watt\n",
    "        \"static_power\": 115 * 0.1,              # Watts per hour\n",
    "        \"pcie_bandwidth\": 16,                   # GB/s\n",
    "        \"memory_bandwidth\": 460                 # GB/s\n",
    "    },\n",
    "    \"alveo_U55C_1_DPU\": {\n",
    "        \"gflops\": (5 / 4) * 1000,               # Peak GFLOPS from datasheet\n",
    "        \"tdp\": 115,                             # TDP in Watts\n",
    "        \"efficiency\": ((5 / 4) * 1000) / 115,   # GFLOPS per Watt\n",
    "        \"static_power\": 115 * 0.1,              # Watts per hour\n",
    "        \"pcie_bandwidth\": 16,                   # GB/s\n",
    "        \"memory_bandwidth\": 460                 # GB/s\n",
    "    },\n",
    "    \"bluefield_3_16C\": {\n",
    "        \"gflops\": 2.1 * 6 * 16,                 # Frequency (in GHz) * ipc * cores\n",
    "        \"tdp\": 150,                             # TDP in Watts\n",
    "        \"efficiency\": (2.1 * 6 * 16) / 150,     # GFLOPS per Watt\n",
    "        \"static_power\": 150 * 0.1,              # Watts per hour\n",
    "        \"pcie_bandwidth\": 64,                   # GB/s\n",
    "        \"memory_bandwidth\": 42                  # GB/s\n",
    "    },\n",
    "    \"bluefield_2_8C\": {\n",
    "        \"gflops\": 2.5 * 3 * 8,                 # Frequency (in GHz) * ipc * cores\n",
    "        \"tdp\": 75,                             # TDP in Watts\n",
    "        \"efficiency\": (2.5 * 3 * 8) / 75,      # GFLOPS per Watt\n",
    "        \"static_power\": 75 * 0.1,              # Watts per hour\n",
    "        \"pcie_bandwidth\": 16,                  # GB/s\n",
    "        \"memory_bandwidth\": 26                 # GB/s\n",
    "    }\n",
    "}\n",
    "\n",
    "d1_model = \"nvidia_L40s\"\n",
    "d2_model = \"nvidia_tesla_T4\"\n",
    "d3_model = \"nvidia_A30\"\n",
    "d4_model = \"alveo_U55C_2_DPU\"\n",
    "d5_model = \"alveo_U55C_1_DPU\"\n",
    "d6_model = \"bluefield_3_16C\"\n",
    "d7_model = \"bluefield_2_8C\"\n",
    "\n",
    "D1_GFLOPS = DEVICE_PROFILE[d1_model][\"gflops\"]\n",
    "D1_TDP = DEVICE_PROFILE[d1_model][\"tdp\"]\n",
    "D1_STATIC_POWER = DEVICE_PROFILE[d1_model][\"static_power\"]\n",
    "D1_EFFICIENCY = DEVICE_PROFILE[d1_model][\"efficiency\"]\n",
    "D1_PCIE_BWDTH = DEVICE_PROFILE[d1_model][\"pcie_bandwidth\"]\n",
    "D1_MEMORY_BWDTH = DEVICE_PROFILE[d1_model][\"memory_bandwidth\"]\n",
    "\n",
    "D2_GFLOPS = DEVICE_PROFILE[d2_model][\"gflops\"]\n",
    "D2_TDP = DEVICE_PROFILE[d2_model][\"tdp\"]\n",
    "D2_STATIC_POWER = DEVICE_PROFILE[d2_model][\"static_power\"]\n",
    "D2_EFFICIENCY = DEVICE_PROFILE[d2_model][\"efficiency\"]\n",
    "D2_PCIE_BWDTH = DEVICE_PROFILE[d2_model][\"pcie_bandwidth\"]\n",
    "D2_MEMORY_BWDTH = DEVICE_PROFILE[d2_model][\"memory_bandwidth\"]\n",
    "\n",
    "D3_GFLOPS = DEVICE_PROFILE[d3_model][\"gflops\"]\n",
    "D3_TDP = DEVICE_PROFILE[d3_model][\"tdp\"]\n",
    "D3_STATIC_POWER = DEVICE_PROFILE[d3_model][\"static_power\"]\n",
    "D3_EFFICIENCY = DEVICE_PROFILE[d3_model][\"efficiency\"]\n",
    "D3_PCIE_BWDTH = DEVICE_PROFILE[d3_model][\"pcie_bandwidth\"]\n",
    "D3_MEMORY_BWDTH = DEVICE_PROFILE[d3_model][\"memory_bandwidth\"]\n",
    "\n",
    "D4_GFLOPS = DEVICE_PROFILE[d4_model][\"gflops\"]\n",
    "D4_TDP = DEVICE_PROFILE[d4_model][\"tdp\"]\n",
    "D4_STATIC_POWER = DEVICE_PROFILE[d4_model][\"static_power\"]\n",
    "D4_EFFICIENCY = DEVICE_PROFILE[d4_model][\"efficiency\"]\n",
    "D4_PCIE_BWDTH = DEVICE_PROFILE[d4_model][\"pcie_bandwidth\"]\n",
    "D4_MEMORY_BWDTH = DEVICE_PROFILE[d4_model][\"memory_bandwidth\"]\n",
    "\n",
    "D5_GFLOPS = DEVICE_PROFILE[d5_model][\"gflops\"]\n",
    "D5_TDP = DEVICE_PROFILE[d5_model][\"tdp\"]\n",
    "D5_STATIC_POWER = DEVICE_PROFILE[d5_model][\"static_power\"]\n",
    "D5_EFFICIENCY = DEVICE_PROFILE[d5_model][\"efficiency\"]\n",
    "D5_PCIE_BWDTH = DEVICE_PROFILE[d5_model][\"pcie_bandwidth\"]\n",
    "D5_MEMORY_BWDTH = DEVICE_PROFILE[d5_model][\"memory_bandwidth\"]\n",
    "\n",
    "D6_GFLOPS = DEVICE_PROFILE[d6_model][\"gflops\"]\n",
    "D6_TDP = DEVICE_PROFILE[d6_model][\"tdp\"]\n",
    "D6_STATIC_POWER = DEVICE_PROFILE[d6_model][\"static_power\"]\n",
    "D6_EFFICIENCY = DEVICE_PROFILE[d6_model][\"efficiency\"]\n",
    "D6_PCIE_BWDTH = DEVICE_PROFILE[d6_model][\"pcie_bandwidth\"]\n",
    "D6_MEMORY_BWDTH = DEVICE_PROFILE[d6_model][\"memory_bandwidth\"]\n",
    "\n",
    "D7_GFLOPS = DEVICE_PROFILE[d7_model][\"gflops\"]\n",
    "D7_TDP = DEVICE_PROFILE[d7_model][\"tdp\"]\n",
    "D7_STATIC_POWER = DEVICE_PROFILE[d7_model][\"static_power\"]\n",
    "D7_EFFICIENCY = DEVICE_PROFILE[d7_model][\"efficiency\"]\n",
    "D7_PCIE_BWDTH = DEVICE_PROFILE[d7_model][\"pcie_bandwidth\"]\n",
    "D7_MEMORY_BWDTH = DEVICE_PROFILE[d7_model][\"memory_bandwidth\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:07:56.181804Z",
     "iopub.status.busy": "2025-06-30T19:07:56.181436Z",
     "iopub.status.idle": "2025-06-30T19:07:56.310072Z",
     "shell.execute_reply": "2025-06-30T19:07:56.308818Z",
     "shell.execute_reply.started": "2025-06-30T19:07:56.181773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx.shape_inference\n",
    "\n",
    "\n",
    "DAG_PROFILE = {\n",
    "    \"computing_time\": {\n",
    "        \"D1\": [],\n",
    "        \"D2\": [],\n",
    "        \"D3\": [],\n",
    "        \"D4\": [],\n",
    "        \"D5\": [],\n",
    "        \"D6\": [],\n",
    "        \"D7\": []\n",
    "    },\n",
    "    \"energy_cost\": {\n",
    "        \"D1\": [],\n",
    "        \"D2\": [],\n",
    "        \"D3\": [],\n",
    "        \"D4\": [],\n",
    "        \"D5\": [],\n",
    "        \"D6\": [],\n",
    "        \"D7\": []\n",
    "    },\n",
    "    \"output_size\": []\n",
    "}\n",
    "\n",
    "def get_input_shapes(model):\n",
    "    input_shapes = {}\n",
    "\n",
    "    for node in model.graph.node:\n",
    "        shape = [dim.dim_value for dim in model.graph.input[0].type.tensor_type.shape.dim]\n",
    "        \n",
    "        if node.name == \"/model.0/conv/Conv\":\n",
    "            input_shapes['images'] = shape\n",
    "        elif node.name == \"/model.23/Sub\":\n",
    "            input_shapes['/model.23/Constant_9_output_0'] = shape\n",
    "        elif node.name == \"/model.23/Add_1\":\n",
    "            input_shapes['/model.23/Constant_10_output_0'] = shape\n",
    "\n",
    "    for value_info in model.graph.value_info:\n",
    "        shape = [dim.dim_value for dim in value_info.type.tensor_type.shape.dim]\n",
    "        input_shapes[value_info.name] = shape\n",
    "\n",
    "    for initializer in model.graph.initializer:\n",
    "        shape = [dim for dim in initializer.dims]\n",
    "        \n",
    "        if initializer.name == '/model.23/Constant_12_output_0':\n",
    "            input_shapes['output'] = shape\n",
    "    \n",
    "    return input_shapes\n",
    "\n",
    "\n",
    "def node_profilling(node, flops, data_size):\n",
    "    # Estimating the intra-device communication overhead in milliseconds (read and write)\n",
    "    d1_memory_overhead = ((data_size / D1_MEMORY_BWDTH) * 2) * 1000\n",
    "    d2_memory_overhead = ((data_size / D2_MEMORY_BWDTH) * 2) * 1000\n",
    "    d3_memory_overhead = ((data_size / D3_MEMORY_BWDTH) * 2) * 1000\n",
    "    d4_memory_overhead = ((data_size / D4_MEMORY_BWDTH) * 2) * 1000\n",
    "    d5_memory_overhead = ((data_size / D5_MEMORY_BWDTH) * 2) * 1000\n",
    "    d6_memory_overhead = ((data_size / D6_MEMORY_BWDTH) * 2) * 1000\n",
    "    d7_memory_overhead = ((data_size / D7_MEMORY_BWDTH) * 2) * 1000\n",
    "\n",
    "    d1_pcie_overhead = (data_size / D1_PCIE_BWDTH) * 1000\n",
    "    d2_pcie_overhead = (data_size / D2_PCIE_BWDTH) * 1000\n",
    "    d3_pcie_overhead = (data_size / D3_PCIE_BWDTH) * 1000\n",
    "    d4_pcie_overhead = (data_size / D4_PCIE_BWDTH) * 1000\n",
    "    d5_pcie_overhead = (data_size / D5_PCIE_BWDTH) * 1000\n",
    "    d6_pcie_overhead = (data_size / D6_PCIE_BWDTH) * 1000\n",
    "    d7_pcie_overhead = (data_size / D7_PCIE_BWDTH) * 1000\n",
    "\n",
    "    # Estimating the computing time in milliseconds\n",
    "    d1_computing_time = (flops / D1_GFLOPS) * 1000\n",
    "    d2_computing_time = (flops / D2_GFLOPS) * 1000\n",
    "    d3_computing_time = (flops / D3_GFLOPS) * 1000\n",
    "    d4_computing_time = (flops / D4_GFLOPS) * 1000\n",
    "    d5_computing_time = (flops / D5_GFLOPS) * 1000\n",
    "    d6_computing_time = (flops / D6_GFLOPS) * 1000\n",
    "    d7_computing_time = (flops / D7_GFLOPS) * 1000\n",
    "    \n",
    "    if node == \"/model.0/conv/Conv\" or node == \"/model.23/Concat_5\":\n",
    "        total_d1_computing_time = d1_computing_time + d1_memory_overhead + d1_pcie_overhead\n",
    "        total_d2_computing_time = d2_computing_time + d2_memory_overhead + d2_pcie_overhead\n",
    "        total_d3_computing_time = d3_computing_time + d3_memory_overhead + d3_pcie_overhead\n",
    "        total_d4_computing_time = d4_computing_time + d4_memory_overhead + d4_pcie_overhead\n",
    "        total_d5_computing_time = d5_computing_time + d5_memory_overhead + d5_pcie_overhead\n",
    "        total_d6_computing_time = d6_computing_time + d6_memory_overhead + d6_pcie_overhead\n",
    "        total_d7_computing_time = d7_computing_time + d7_memory_overhead + d7_pcie_overhead\n",
    "    else:\n",
    "        total_d1_computing_time = d1_computing_time + d1_memory_overhead\n",
    "        total_d2_computing_time = d2_computing_time + d2_memory_overhead\n",
    "        total_d3_computing_time = d3_computing_time + d3_memory_overhead\n",
    "        total_d4_computing_time = d4_computing_time + d4_memory_overhead\n",
    "        total_d5_computing_time = d5_computing_time + d5_memory_overhead\n",
    "        total_d6_computing_time = d6_computing_time + d6_memory_overhead\n",
    "        total_d7_computing_time = d7_computing_time + d7_memory_overhead\n",
    "\n",
    "    DAG_PROFILE[\"computing_time\"][\"D1\"].append(total_d1_computing_time)\n",
    "    DAG_PROFILE[\"computing_time\"][\"D2\"].append(total_d2_computing_time)\n",
    "    DAG_PROFILE[\"computing_time\"][\"D3\"].append(total_d3_computing_time)\n",
    "    DAG_PROFILE[\"computing_time\"][\"D4\"].append(total_d4_computing_time)\n",
    "    DAG_PROFILE[\"computing_time\"][\"D5\"].append(total_d5_computing_time)\n",
    "    DAG_PROFILE[\"computing_time\"][\"D6\"].append(total_d6_computing_time)\n",
    "    DAG_PROFILE[\"computing_time\"][\"D7\"].append(total_d7_computing_time)\n",
    "    \n",
    "    # Estimating the energy cost in Joules\n",
    "    d1_energy_cost = (total_d1_computing_time / 1000) * D1_TDP\n",
    "    d2_energy_cost = (total_d2_computing_time / 1000) * D2_TDP\n",
    "    d3_energy_cost = (total_d3_computing_time / 1000) * D3_TDP\n",
    "    d4_energy_cost = (total_d4_computing_time / 1000) * D4_TDP\n",
    "    d5_energy_cost = (total_d5_computing_time / 1000) * D5_TDP\n",
    "    d6_energy_cost = (total_d6_computing_time / 1000) * D6_TDP\n",
    "    d7_energy_cost = (total_d7_computing_time / 1000) * D7_TDP\n",
    "\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D1\"].append(d1_energy_cost)\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D2\"].append(d2_energy_cost)\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D3\"].append(d3_energy_cost)\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D4\"].append(d4_energy_cost)\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D5\"].append(d5_energy_cost)\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D6\"].append(d6_energy_cost)\n",
    "    DAG_PROFILE[\"energy_cost\"][\"D7\"].append(d7_energy_cost)\n",
    "\n",
    "    DAG_PROFILE[\"output_size\"].append(data_size)\n",
    "    \n",
    "    print(\"\\n=========================================================\")\n",
    "    \n",
    "    print(\"\\nNode {0} computing complexity: {1:.4f} GFLOPs\".format(node, flops))\n",
    "\n",
    "    print(\"Energy cost (D1 - {0}): {1:.4f} J\".format(d1_model, d1_energy_cost))\n",
    "    print(\"Energy cost (D2 - {0}): {1:.4f} J\".format(d2_model, d2_energy_cost))\n",
    "    print(\"Energy cost (D3 - {0}): {1:.4f} J\".format(d3_model, d3_energy_cost))\n",
    "    print(\"Energy cost (D4 - {0}): {1:.4f} J\".format(d4_model, d4_energy_cost))\n",
    "    print(\"Energy cost (D5 - {0}): {1:.4f} J\".format(d5_model, d5_energy_cost))\n",
    "    print(\"Energy cost (D6 - {0}): {1:.4f} J\".format(d6_model, d6_energy_cost))\n",
    "    print(\"Energy cost (D7 - {0}): {1:.4f} J\".format(d7_model, d7_energy_cost))\n",
    "\n",
    "    print(\"Computing time (D1 - {0}): {1:.4} ms\".format(d1_model, total_d1_computing_time))\n",
    "    print(\"Computing time (D2 - {0}): {1:.4} ms\".format(d2_model, total_d2_computing_time))\n",
    "    print(\"Computing time (D3 - {0}): {1:.4} ms\".format(d3_model, total_d3_computing_time))\n",
    "    print(\"Computing time (D4 - {0}): {1:.4} ms\".format(d4_model, total_d4_computing_time))\n",
    "    print(\"Computing time (D5 - {0}): {1:.4} ms\".format(d5_model, total_d5_computing_time))\n",
    "    print(\"Computing time (D6 - {0}): {1:.4} ms\".format(d6_model, total_d6_computing_time))\n",
    "    print(\"Computing time (D7 - {0}): {1:.4} ms\".format(d7_model, total_d7_computing_time))\n",
    "    \n",
    "    print(\"\\n=========================================================\\n\")\n",
    "\n",
    "\n",
    "def estimate_flops(model):\n",
    "    model = onnx.shape_inference.infer_shapes(model)\n",
    "    input_shapes = get_input_shapes(model)\n",
    "    \n",
    "    total_flops = 0\n",
    "    total_data = 0\n",
    "    \n",
    "    node_flops = {}\n",
    "\n",
    "    for node in model.graph.node:\n",
    "        print(\"Operation type: {0}\".format(node.op_type))\n",
    "\n",
    "        input_shape = input_shapes[node.input[0]]\n",
    "        output_shape = input_shapes[node.output[0]]\n",
    "\n",
    "        if node.op_type == \"Conv\":            \n",
    "            c_in = input_shape[1]\n",
    "            \n",
    "            kernel_height = [attr.ints for attr in node.attribute if attr.name == 'kernel_shape'][0][0]\n",
    "            kernel_width = [attr.ints for attr in node.attribute if attr.name == 'kernel_shape'][0][1]\n",
    "            \n",
    "            c_out = output_shape[1]\n",
    "            h_out = output_shape[2]\n",
    "            w_out = output_shape[3]\n",
    "\n",
    "            macs = (c_out * h_out * w_out) * (c_in * kernel_height * kernel_width)\n",
    "            flops = 2 * macs / (10 ** 9)\n",
    "\n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "            print(\"c_in: {0}, c_out: {1}, kernel_height: {2}\".format(c_in, c_out, kernel_height))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "            \n",
    "            node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Sigmoid\":\n",
    "            if len(output_shape) > 3:                \n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "\n",
    "                flops = 4 * (c_out * h_out * w_out) / (10 ** 9)\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "\n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = 4 * (channels * length) / (10 ** 9)\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Mul\":\n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "\n",
    "                flops = c_out * h_out * w_out / (10 ** 9)\n",
    "                \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = channels * length / (10 ** 9)\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Add\":\n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "\n",
    "                flops = c_out * h_out * w_out / (10 ** 9)\n",
    "                \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = channels * length / (10 ** 9)\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "\n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Sub\":\n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "\n",
    "                flops = c_out * h_out * w_out / (10 ** 9)\n",
    "                \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = channels * length / (10 ** 9)\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Div\":\n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "\n",
    "                flops = c_out * h_out * w_out / (10 ** 9)\n",
    "                \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = channels * length / (10 ** 9)\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"MatMul\":\n",
    "            c_out = output_shape[1]\n",
    "            h_out = output_shape[2]\n",
    "            w_out = output_shape[3]\n",
    "\n",
    "            macs = c_out * h_out * w_out\n",
    "            flops = 2 * macs / (10 ** 9)\n",
    "\n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input, node.output[0], flops))\n",
    "            print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "            \n",
    "            node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"MaxPool\":\n",
    "            c_out = output_shape[1]\n",
    "            h_out = output_shape[2]\n",
    "            w_out = output_shape[3]\n",
    "\n",
    "            kernel_height = [attr.ints for attr in node.attribute if attr.name == 'kernel_shape'][0][0]\n",
    "            kernel_width = [attr.ints for attr in node.attribute if attr.name == 'kernel_shape'][0][1]\n",
    "\n",
    "            flops = (c_out * h_out * w_out) * (kernel_height * kernel_width - 1) / (10 ** 9)\n",
    "            \n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "            print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "            \n",
    "            node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Softmax\":\n",
    "            c_out = output_shape[1]\n",
    "            h_out = output_shape[2]\n",
    "            w_out = output_shape[3]\n",
    "\n",
    "            output_elements = c_out * h_out * w_out\n",
    "            elements_in_softmax_axis = output_shape[-1]\n",
    "            num_slices = output_elements // elements_in_softmax_axis\n",
    "\n",
    "            # 3 FLOPs per element in the softmax vector (exp, add, div)\n",
    "            flops_per_slice = 3 * elements_in_softmax_axis\n",
    "            \n",
    "            flops = num_slices * flops_per_slice / (10 ** 9)\n",
    "\n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = output_elements * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "            print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "            \n",
    "            node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Resize\":\n",
    "            for attr in node.attribute:\n",
    "                if attr.name == \"mode\":\n",
    "                    print(f\"Resize mode: {attr.s.decode('utf-8')}\")\n",
    "\n",
    "            c_out = output_shape[1]\n",
    "            h_out = output_shape[2]\n",
    "            w_out = output_shape[3]\n",
    "\n",
    "            output_elements = c_out * h_out * w_out\n",
    "\n",
    "            # 1 FLOP per element (nearest neighbor interpolation mode)\n",
    "            flops = 1 * output_elements / (10 ** 9)\n",
    "\n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = output_elements * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "            print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "            \n",
    "            node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Split\":            \n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "    \n",
    "                flops = 0\n",
    "    \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                \n",
    "                data_size = data_size * 2 # Considering the data size of both splits\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = 0\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                \n",
    "                data_size = data_size * 2 # Considering the data size of both splits\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Slice\":\n",
    "            channels = output_shape[1]\n",
    "            length = output_shape[2]\n",
    "\n",
    "            flops = 0\n",
    "\n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "            print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "\n",
    "            node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Concat\":\n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "    \n",
    "                flops = 0\n",
    "    \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = 0\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Reshape\":\n",
    "            if len(output_shape) > 3:\n",
    "                c_out = output_shape[1]\n",
    "                h_out = output_shape[2]\n",
    "                w_out = output_shape[3]\n",
    "    \n",
    "                flops = 0\n",
    "    \n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "            else:\n",
    "                channels = output_shape[1]\n",
    "                length = output_shape[2]\n",
    "\n",
    "                flops = 0\n",
    "\n",
    "                total_flops += flops\n",
    "                node_flops[node.name] = flops\n",
    "\n",
    "                # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "                data_size = (channels * length) * 4 / (10 ** 9) # GB\n",
    "                total_data += data_size\n",
    "    \n",
    "                print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "                print(\"c_out: {0}, W': {1}\".format(channels, length))\n",
    "                print(f\"intermediate result data size: {data_size} GB\")\n",
    "                \n",
    "                node_profilling(node.name, flops, data_size)\n",
    "        elif node.op_type == \"Transpose\":\n",
    "            c_out = output_shape[1]\n",
    "            h_out = output_shape[2]\n",
    "            w_out = output_shape[3]\n",
    "\n",
    "            flops = 0\n",
    "\n",
    "            total_flops += flops\n",
    "            node_flops[node.name] = flops\n",
    "\n",
    "            # Output elements multiplied by the numerical preicsion byte size (FP32)\n",
    "            data_size = (c_out * h_out * w_out) * 4 / (10 ** 9) # GB\n",
    "            total_data += data_size\n",
    "\n",
    "            print(\"node: {0}, input: {1}, output: {2}, GFLOPs: {3:.4f}\".format(node.name, node.input[0], node.output[0], flops))\n",
    "            print(\"c_out: {0}, H': {1}, W': {2}\".format(c_out, h_out, w_out))\n",
    "            print(f\"intermediate result data size: {data_size} GB\")\n",
    "            \n",
    "            node_profilling(node.name, flops, data_size)\n",
    "\n",
    "    print(\"\\n=========================================================\")\n",
    "    \n",
    "    print(\"\\nDAG computing complexity: {0:.4f} GFLOPs\".format(total_flops))\n",
    "\n",
    "    print(\"Energy cost (D1 - {0}): {1:.4} J\".format(d1_model, sum(DAG_PROFILE[\"energy_cost\"][\"D1\"])))\n",
    "    print(\"Energy cost (D2 - {0}): {1:.4} J\".format(d2_model, sum(DAG_PROFILE[\"energy_cost\"][\"D2\"])))\n",
    "    print(\"Energy cost (D3 - {0}): {1:.4} J\".format(d3_model, sum(DAG_PROFILE[\"energy_cost\"][\"D3\"])))\n",
    "    print(\"Energy cost (D4 - {0}): {1:.4} J\".format(d4_model, sum(DAG_PROFILE[\"energy_cost\"][\"D4\"])))\n",
    "    print(\"Energy cost (D5 - {0}): {1:.4} J\".format(d5_model, sum(DAG_PROFILE[\"energy_cost\"][\"D5\"])))\n",
    "    print(\"Energy cost (D6 - {0}): {1:.4} J\".format(d6_model, sum(DAG_PROFILE[\"energy_cost\"][\"D6\"])))\n",
    "    print(\"Energy cost (D7 - {0}): {1:.4} J\".format(d7_model, sum(DAG_PROFILE[\"energy_cost\"][\"D7\"])))\n",
    "\n",
    "    print(\"Computing time (D1 - {0}): {1:.4} ms\".format(d1_model, sum(DAG_PROFILE[\"computing_time\"][\"D1\"])))\n",
    "    print(\"Computing time (D2 - {0}): {1:.4} ms\".format(d2_model, sum(DAG_PROFILE[\"computing_time\"][\"D2\"])))\n",
    "    print(\"Computing time (D3 - {0}): {1:.4} ms\".format(d3_model, sum(DAG_PROFILE[\"computing_time\"][\"D3\"])))\n",
    "    print(\"Computing time (D4 - {0}): {1:.4} ms\".format(d4_model, sum(DAG_PROFILE[\"computing_time\"][\"D4\"])))\n",
    "    print(\"Computing time (D5 - {0}): {1:.4} ms\".format(d5_model, sum(DAG_PROFILE[\"computing_time\"][\"D5\"])))\n",
    "    print(\"Computing time (D6 - {0}): {1:.4} ms\".format(d6_model, sum(DAG_PROFILE[\"computing_time\"][\"D6\"])))\n",
    "    print(\"Computing time (D7 - {0}): {1:.4} ms\".format(d7_model, sum(DAG_PROFILE[\"computing_time\"][\"D7\"])))\n",
    "    \n",
    "    print(\"\\n=========================================================\\n\")\n",
    "\n",
    "    return node_flops\n",
    "        \n",
    "        \n",
    "node_flops = estimate_flops(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optimization Problem Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:08:42.540685Z",
     "iopub.status.busy": "2025-06-30T19:08:42.540260Z",
     "iopub.status.idle": "2025-06-30T19:08:43.779510Z",
     "shell.execute_reply": "2025-06-30T19:08:43.777743Z",
     "shell.execute_reply.started": "2025-06-30T19:08:42.540657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def verify_solution(nodes, devices, node_energy, node_energy_acc, node_latency, node_flops, x, overall_latency_requirement, node_assignments, plot_summary=False, exp=0):\n",
    "    # Initialize dictionaries to store counts and summaries\n",
    "    device_node_count = {device: 0 for device in devices}\n",
    "    flops_per_device = {device: 0 for device in devices}\n",
    "    total_latency = {device: 0 for device in devices}\n",
    "    total_energy = {device: 0 for device in devices}\n",
    "    total_acc_energy = {device: 0 for device in devices}\n",
    "\n",
    "    device_type_to_model = {\n",
    "        \"D1\": d1_model,\n",
    "        \"D2\": d2_model,\n",
    "        \"D3\": d3_model,\n",
    "        \"D4\": d4_model,\n",
    "        \"D5\": d5_model,\n",
    "        \"D6\": d6_model,\n",
    "        \"D7\": d7_model\n",
    "    }\n",
    "\n",
    "    # Calculate and summarize information\n",
    "    for i, node in enumerate(nodes):\n",
    "        assigned_device = node_assignments[node]\n",
    "        device_node_count[assigned_device] += 1\n",
    "\n",
    "        for j, device in enumerate(devices):\n",
    "            if x[(i, j)].solution_value() > 0:\n",
    "                total_latency[device] += node_latency[device][i]\n",
    "                total_energy[device] += node_energy[device][i]\n",
    "                total_acc_energy[device] += node_energy_acc[device][i]\n",
    "    \n",
    "    for node, device in node_assignments.items():\n",
    "        if node in node_flops: \n",
    "            flops_per_device[device] += node_flops[node]\n",
    "\n",
    "    # Check latency requirements\n",
    "    meets_latency_requirements = all(latency <= overall_latency_requirement for latency in total_latency.values())\n",
    "\n",
    "    # Print results\n",
    "    print(\"Meets Latency Requirements:\", meets_latency_requirements)\n",
    "\n",
    "    print(\"\\nSolution Verification Summary:\\n\")\n",
    "    for device in devices:\n",
    "        print(f\" Device: {device_type_to_model[device]}\")\n",
    "        print(f\" Number of Nodes Assigned: {device_node_count[device]}\")\n",
    "        print(f\" GFLOPs computed: {flops_per_device[device]:.4f}\")\n",
    "        print(f\" Total computing time: {total_latency[device]:.4f} ms\")\n",
    "        print(f\" Total energy cost: {total_energy[device]:.4f} J\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    print(\"\\nTotal Latency: {0:.4f} milliseconds\".format(sum(total_latency.values())))\n",
    "    print(\"Total Energy: {0:.4f} J\".format(sum(total_energy.values())))\n",
    "\n",
    "    if plot_summary == True:\n",
    "        # Plot pie charts\n",
    "        plot_chart(flops_per_device, \"FLOPs computed per device\", \"Devices\", \"FLOPs\", exp)\n",
    "        plot_chart(total_latency, \"Total computing time per device\", \"Devices\", \"Computing time (ms)\", exp)\n",
    "        plot_chart(total_acc_energy, \"Total computing energy per device\", \"Devices\", \"Energy (J)\", exp) \n",
    "    \n",
    "    \n",
    "def plot_chart(data, title, xlabel, ylabel, exp): \n",
    "    labels = list(data.keys()) \n",
    "    data = list(data.values())\n",
    "\n",
    "    # Get four different grey colors.\n",
    "    cmap = plt.get_cmap('magma')\n",
    "    colors = list(cmap(np.linspace(0.1, 0.9, len(devices))))\n",
    "\n",
    "    #data = [np.round(i, 4) for i in data]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    rects = plt.bar(labels, data, color=colors)\n",
    "    plt.bar_label(rects, padding=3)\n",
    "    sns.despine()\n",
    "    plt.xlabel(xlabel) \n",
    "    plt.ylabel(ylabel) \n",
    "    \n",
    "    plt.title(title, fontsize=16, pad=30)\n",
    "\n",
    "    #plt.savefig(\"{0}_e{1}.pdf\".format(title, exp), dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:10:23.933148Z",
     "iopub.status.busy": "2025-06-30T19:10:23.932712Z",
     "iopub.status.idle": "2025-06-30T19:11:30.713976Z",
     "shell.execute_reply": "2025-06-30T19:11:30.712978Z",
     "shell.execute_reply.started": "2025-06-30T19:10:23.933119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def extract_dag_edges(model):\n",
    "    output_to_node = {}\n",
    "    edges = []\n",
    "    \n",
    "    for idx, node in enumerate(model.graph.node):\n",
    "        for output in node.output:\n",
    "            output_to_node[output] = idx\n",
    "    \n",
    "    for idx, node in enumerate(model.graph.node):\n",
    "        for input_name in node.input:\n",
    "            if input_name in output_to_node:\n",
    "                parent = output_to_node[input_name]\n",
    "                child = idx\n",
    "                edges.append((parent, child))\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "def nested_dict():\n",
    "    return defaultdict(dict)\n",
    "\n",
    "\n",
    "def estimate_communication_latencies(devices, edges):\n",
    "    comm_latency = defaultdict(lambda: defaultdict(nested_dict))\n",
    "\n",
    "    device_type_to_model = {\n",
    "        \"D1\": d1_model,\n",
    "        \"D2\": d2_model,\n",
    "        \"D3\": d3_model,\n",
    "        \"D4\": d4_model,\n",
    "        \"D5\": d5_model,\n",
    "        \"D6\": d6_model,\n",
    "        \"D7\": d7_model\n",
    "    }\n",
    "\n",
    "    for device_from in devices:\n",
    "        for device_to in devices:\n",
    "            model_from = device_type_to_model[device_from]\n",
    "            model_to = device_type_to_model[device_to]\n",
    "\n",
    "            bandwidth = min(\n",
    "                DEVICE_PROFILE[model_from][\"pcie_bandwidth\"],\n",
    "                DEVICE_PROFILE[model_to][\"pcie_bandwidth\"]\n",
    "            )\n",
    "    \n",
    "            for (parent, child) in edges:\n",
    "                data_size = DAG_PROFILE[\"output_size\"][parent]\n",
    "                latency = 0 if device_from == device_to else (data_size / bandwidth) * 1000\n",
    "                comm_latency[device_from][device_to][parent][child] = latency\n",
    "\n",
    "    return comm_latency\n",
    "\n",
    "\n",
    "def graph_partition_S1(model, nodes, devices, node_energy, node_flops, node_latency, overall_latency_requirement, device_capacity, device_utilization, static_energy, plot_summary=True, exp=0):\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    solver.EnableOutput()\n",
    "\n",
    "    solver.set_time_limit(86400000)\n",
    "    \n",
    "    available_capacity = {device: device_capacity[device] * (1.0 - device_utilization[device]) for device in devices}\n",
    "    adjusted_node_latency = {}\n",
    "\n",
    "    for device in devices:\n",
    "        adjusted_node_latency[device] = [node_latency[device][i] / (1.0 - device_utilization[device]) for i in range(len(node_latency[device]))]\n",
    "\n",
    "    T_s = overall_latency_requirement / 1000\n",
    "    \n",
    "    # Variables: x[i][j] represents if node i is assigned to device j (binary)\n",
    "    x = {}\n",
    "    \n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            x[(i, j)] = solver.BoolVar(f'x_{i}_{j}')\n",
    "    \n",
    "    # Objective: Minimize total energy spent (dynamic energy + static energy)\n",
    "    objective = solver.Objective()\n",
    "    \n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            # Scaling both dynamic and static energy by the device utilization\n",
    "            dynamic_energy = node_energy[devices[j]][i] * (adjusted_node_latency[devices[j]][i] / node_latency[devices[j]][i])\n",
    "            static_energy_per_node = (adjusted_node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "            \n",
    "            objective.SetCoefficient(x[(i, j)], dynamic_energy + static_energy_per_node)\n",
    "    \n",
    "    objective.SetMinimization()\n",
    "    \n",
    "    # Consistency constraint: each node must be assigned to exactly one device\n",
    "    for i in range(len(nodes)):\n",
    "        solver.Add(sum(x[(i, j)] for j in range(len(devices))) == 1)\n",
    "    \n",
    "    # Device capacity constraint: the workload assigned to each device (in GFLOPs) should\n",
    "    # not surpass its computational capacity (in GFLOPS)\n",
    "    for j, device in enumerate(devices):        \n",
    "        solver.Add(sum(x[(i, j)] * node_flops[node] for i, node in enumerate(nodes)) <= (available_capacity[device] * T_s))\n",
    " \n",
    "    # Node precedence constraint: if there are dependencies between nodes, the child node\n",
    "    # processing must not start before its parent node finishes\n",
    "    \n",
    "    # Defining start time variables\n",
    "    s = [solver.NumVar(0, overall_latency_requirement, f\"s_{i}\") for i in range(len(nodes))]\n",
    "\n",
    "    # Maximum possible finish time (e.g. sum of all node latencies on the slowest device)\n",
    "    M = sum(max(adjusted_node_latency[device][i] for device in devices) for i in range(len(nodes)))\n",
    "\n",
    "    # Node dependencies\n",
    "    edges = extract_dag_edges(model)\n",
    "\n",
    "    # Inter-device communication overhead\n",
    "    comm_latency = estimate_communication_latencies(devices, edges)\n",
    "\n",
    "    for (parent, child) in edges:\n",
    "        for j, device_p in enumerate(devices):\n",
    "            for k, device_c in enumerate(devices):\n",
    "                # transfer penalty if parent -> child crosses devices\n",
    "                transfer = (0 if device_p == device_c else comm_latency[device_p][device_c][parent][child])\n",
    "          \n",
    "                # activate only when parent -> device_p AND child -> device_c\n",
    "                solver.Add(s[child] >= s[parent] + adjusted_node_latency[device_p][parent] + transfer - M * (2 - x[(parent, j)] - x[(child, k)]))\n",
    "\n",
    "    # Global latency constraint: the total completion time (including intra- and inter-device comm. overhead)\n",
    "    # should meet the overall latency requirement\n",
    "    for i in range(len(nodes)):\n",
    "        # completion = s[i] + its compute time on whichever device it's assigned\n",
    "        completion_time = s[i] + sum(x[(i, j)] * adjusted_node_latency[devices[j]][i] for j in range(len(devices)))\n",
    "        solver.Add(completion_time <= overall_latency_requirement)\n",
    "\n",
    "    # Non-Parallelism constraint: each device can only process one node at time\n",
    "    \n",
    "    # Building a representation of the DAG reachability\n",
    "    adj = {i: [] for i in range(len(nodes))}\n",
    "    for parent, child in edges:\n",
    "        adj[parent].append(child)\n",
    "    \n",
    "    # For each node, find all other nodes it can reach (its descendants).\n",
    "    reachable = {i: set() for i in range(len(nodes))}\n",
    "    for i in range(len(nodes)):\n",
    "            q = [i]\n",
    "            visited = {i}\n",
    "            while q:\n",
    "                u = q.pop(0)\n",
    "                for v in adj.get(u, []):\n",
    "                    if v not in visited:\n",
    "                        visited.add(v)\n",
    "                        reachable[i].add(v)\n",
    "                        q.append(v)\n",
    "    \n",
    "    # Identifying pairs (i, j) that are independent\n",
    "    independent_pairs = []\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            # If i cannot reach j, AND j cannot reach i, they are independent.\n",
    "            if j not in reachable[i] and i not in reachable[j]:\n",
    "                independent_pairs.append((i, j))\n",
    "    \n",
    "    # Only loop through the independent pairs you found.\n",
    "    for i, j in independent_pairs:\n",
    "        for d_idx, device in enumerate(devices):\n",
    "            li = adjusted_node_latency[device][i]\n",
    "            lj = adjusted_node_latency[device][j]\n",
    "\n",
    "            # This binary variable decides the order ONLY for this independent pair.\n",
    "            b = solver.BoolVar(f\"order_{i}_{j}_on_{device}\")\n",
    "    \n",
    "            # This is the \"Big M\" formulation. It correctly activates the constraints \n",
    "            # only when BOTH nodes are on the SAME device.\n",
    "            EPS = 1e-6\n",
    "            \n",
    "            # Constraint 1: If i is before j (b=1)\n",
    "            # The term (3 - x_i - x_j - b) becomes 0 only if x_i=1, x_j=1, and b=1.\n",
    "            # Otherwise, the term is >= 1, making the constraint trivial.\n",
    "            solver.Add(s[i] + li + EPS <= s[j] + M * (3 - x[(i, d_idx)] - x[(j, d_idx)] - b))\n",
    "            \n",
    "            # Constraint 2: If j is before i (b=0)\n",
    "            # The term (2 - x_i - x_j + b) becomes 0 only if x_i=1, x_j=1, and b=0.\n",
    "            # Otherwise, the term is >= 1, making the constraint trivial.\n",
    "            solver.Add(s[j] + lj + EPS <= s[i] + M * (2 - x[(i, d_idx)] - x[(j, d_idx)] + b))\n",
    "\n",
    "    # Solve the problem\n",
    "    status = solver.Solve()\n",
    "\n",
    "    START_TIME = {}\n",
    "    END_TIME = {}\n",
    "    MAX_TIME = 0\n",
    "    \n",
    "    for i in range(len(nodes)):\n",
    "        completion_time = s[i].solution_value() + sum(x[(i, j)].solution_value() * adjusted_node_latency[devices[j]][i] for j in range(len(devices)))\n",
    "        START_TIME[i] = s[i].solution_value()\n",
    "        END_TIME[i] = completion_time\n",
    "        \n",
    "        if (completion_time > MAX_TIME):\n",
    "            MAX_TIME = completion_time\n",
    "    \n",
    "    print(f\"\\nNode processing MAX TIME:{MAX_TIME}:.3f\")\n",
    "\n",
    "    node_assignments = {}\n",
    "    x_list = []\n",
    "    \n",
    "    if status == solver.OPTIMAL:\n",
    "        print('Solution:')\n",
    "        \n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(devices)):\n",
    "                if x[(i, j)].solution_value() > 0:\n",
    "                    node_assignments[nodes[i]] = devices[j]\n",
    "                    x_list.append((i, j))\n",
    "                    print(f'Node {nodes[i]} assigned to {devices[j]}')\n",
    "        \n",
    "        print('Objective value =', objective.Value())\n",
    "\n",
    "        print(\"\\nPrecedence constraint sanity check:\")\n",
    "        for (parent, child) in edges:\n",
    "            for j, device_p in enumerate(devices):\n",
    "                for k, device_c in enumerate(devices):\n",
    "                    if x[(parent, j)].solution_value() == 1 and x[(child, k)].solution_value() == 1:\n",
    "                        start_p = s[parent].solution_value()\n",
    "                        start_c = s[child].solution_value()\n",
    "                        \n",
    "                        latency = adjusted_node_latency[device_p][parent]\n",
    "                        \n",
    "                        transfer = 0 if device_p == device_c else comm_latency[device_p][device_c][parent][child]\n",
    "                        expected_min_start = start_p + latency + transfer\n",
    "                        \n",
    "                        print(f\"\\nEdge {parent}  {child} across {devices[j]}  {devices[k]}\")\n",
    "                        print(f\"  s[{parent}] = {start_p:.3f}, s[{child}] = {start_c:.3f}, must be  {expected_min_start:.3f}\")\n",
    "                        \n",
    "                        assert start_c + 1e-4 >= expected_min_start, \"Constraint violated!\"\n",
    "\n",
    "        print(\"\\nNon-parallelism constraint sanity check:\")\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(i + 1, len(nodes)):\n",
    "                # Skip if there's a dependency in either direction\n",
    "                if j in reachable[i] or i in reachable[j]:\n",
    "                    continue \n",
    "        \n",
    "                for d_idx, device in enumerate(devices):\n",
    "                    if x[(i, d_idx)].solution_value() == 1 and x[(j, d_idx)].solution_value() == 1:\n",
    "                        s_i = s[i].solution_value()\n",
    "                        s_j = s[j].solution_value()\n",
    "                        li = adjusted_node_latency[device][i]\n",
    "                        lj = adjusted_node_latency[device][j]\n",
    "        \n",
    "                        finish_i = s_i + li\n",
    "                        finish_j = s_j + lj\n",
    "        \n",
    "                        overlap = not (finish_i <= s_j or finish_j <= s_i)\n",
    "        \n",
    "                        print(f\"\\nDevice {device}: Node {i} [{s_i:.3f}, {finish_i:.3f}) \"\n",
    "                              f\"vs Node {j} [{s_j:.3f}, {finish_j:.3f})\")\n",
    "                        \n",
    "                        if overlap:\n",
    "                            print(\"Overlap detected!\")\n",
    "                        else:\n",
    "                            print(\"No overlap  constraint respected\")\n",
    "        \n",
    "                        assert not overlap, f\"Nodes {i} and {j} overlap on device {device}\"\n",
    "        \n",
    "        node_energy_acc = {\n",
    "            \"D1\": [],\n",
    "            \"D2\": [],\n",
    "            \"D3\": [],\n",
    "            \"D4\": [],\n",
    "            \"D5\": [],\n",
    "            \"D6\": [],\n",
    "            \"D7\": []\n",
    "        }\n",
    "\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(devices)):\n",
    "                dynamic_energy = node_energy[devices[j]][i]\n",
    "                static_energy_per_node = (node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "                \n",
    "                node_energy_acc[devices[j]].append(dynamic_energy + static_energy_per_node)\n",
    "    \n",
    "        print(\"\\n=========================================================\\n\")\n",
    "        verify_solution(nodes, devices, node_energy, node_energy_acc, node_latency,\n",
    "                        node_flops, x, overall_latency_requirement, node_assignments, plot_summary, exp)\n",
    "        print(\"\\n=========================================================\\n\")\n",
    "\n",
    "        return objective.Value(), MAX_TIME, START_TIME, END_TIME, [nodes, devices, node_energy, node_energy_acc, node_latency,\n",
    "                                                                   node_flops, x_list, overall_latency_requirement, node_assignments]\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def graph_partition_S2(model, nodes, devices, node_energy, node_flops, node_latency, overall_latency_requirement, device_capacity, device_utilization, static_energy, opt_obj, plot_summary=True, exp=0):\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    solver.EnableOutput()\n",
    "\n",
    "    solver.set_time_limit(86400000)\n",
    "    \n",
    "    available_capacity = {device: device_capacity[device] * (1.0 - device_utilization[device]) for device in devices}\n",
    "    adjusted_node_latency = {}\n",
    "\n",
    "    for device in devices:\n",
    "        adjusted_node_latency[device] = [node_latency[device][i] / (1.0 - device_utilization[device]) for i in range(len(node_latency[device]))]\n",
    "\n",
    "    T_s = overall_latency_requirement / 1000\n",
    "    \n",
    "    # Variables: x[i][j] represents if node i is assigned to device j (binary)\n",
    "    x = {}\n",
    "    \n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            x[(i, j)] = solver.BoolVar(f'x_{i}_{j}')\n",
    "\n",
    "    # Defining start time variables\n",
    "    s = [solver.NumVar(0, overall_latency_requirement, f\"s_{i}\") for i in range(len(nodes))]\n",
    "    \n",
    "    # Objective: Minimize completion time\n",
    "    objective = solver.Objective()\n",
    "\n",
    "    completion_time = solver.NumVar(0, solver.infinity(), 'completion_time')\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            expr = s[i] + x[(i, j)] * adjusted_node_latency[devices[j]][i]\n",
    "            solver.Add(completion_time >= expr)\n",
    "\n",
    "    objective.SetCoefficient(completion_time, 1)\n",
    "    objective.SetMinimization()\n",
    "\n",
    "    # Energy expression: total energy consumed across all node-device assignments\n",
    "    energy_terms = []\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            # Scaling both dynamic and static energy by the device utilization\n",
    "            dynamic = node_energy[devices[j]][i] * (adjusted_node_latency[devices[j]][i] / node_latency[devices[j]][i])\n",
    "            static_per_node = (adjusted_node_latency[devices[j]][i] / 1000) * static_energy[devices[j]] # Convert ms to seconds\n",
    "\n",
    "            energy = x[(i, j)] * (dynamic + static_per_node)\n",
    "            energy_terms.append(energy)\n",
    "\n",
    "    # Constraint: total energy must match optimal value from Stage 1\n",
    "    energy_expr = solver.Sum(energy_terms)\n",
    "    solver.Add(energy_expr == opt_obj)\n",
    "\n",
    "    # Consistency constraint: each node must be assigned to exactly one device\n",
    "    for i in range(len(nodes)):\n",
    "        solver.Add(sum(x[(i, j)] for j in range(len(devices))) == 1)\n",
    "    \n",
    "    # Device capacity constraint: the workload assigned to each device (in GFLOPs) should\n",
    "    # not surpass its computational capacity (in GFLOPS)\n",
    "    for j, device in enumerate(devices):        \n",
    "        solver.Add(sum(x[(i, j)] * node_flops[node] for i, node in enumerate(nodes)) <= (available_capacity[device] * T_s))\n",
    " \n",
    "    # Node precedence constraint: if there are dependencies between nodes, the child node\n",
    "    # processing must not start before its parent node finishes\n",
    "\n",
    "    # Maximum possible finish time (e.g. sum of all node latencies on the slowest device)\n",
    "    M = sum(max(adjusted_node_latency[device][i] for device in devices) for i in range(len(nodes)))\n",
    "\n",
    "    # Node dependencies\n",
    "    edges = extract_dag_edges(model)\n",
    "\n",
    "    # Inter-device communication overhead\n",
    "    comm_latency = estimate_communication_latencies(devices, edges)\n",
    "\n",
    "    for (parent, child) in edges:\n",
    "        for j, device_p in enumerate(devices):\n",
    "            for k, device_c in enumerate(devices):\n",
    "                # transfer penalty if parent -> child crosses devices\n",
    "                transfer = (0 if device_p == device_c else comm_latency[device_p][device_c][parent][child])\n",
    "          \n",
    "                # activate only when parent -> device_p AND child -> device_c\n",
    "                solver.Add(s[child] >= s[parent] + adjusted_node_latency[device_p][parent] + transfer - M * (2 - x[(parent, j)] - x[(child, k)]))\n",
    "\n",
    "    # Non-Parallelism constraint: each device can only process one node at time\n",
    "    \n",
    "    # Building a representation of the DAG reachability\n",
    "    adj = {i: [] for i in range(len(nodes))}\n",
    "    for parent, child in edges:\n",
    "        adj[parent].append(child)\n",
    "    \n",
    "    # For each node, find all other nodes it can reach (its descendants).\n",
    "    reachable = {i: set() for i in range(len(nodes))}\n",
    "    for i in range(len(nodes)):\n",
    "            q = [i]\n",
    "            visited = {i}\n",
    "            while q:\n",
    "                u = q.pop(0)\n",
    "                for v in adj.get(u, []):\n",
    "                    if v not in visited:\n",
    "                        visited.add(v)\n",
    "                        reachable[i].add(v)\n",
    "                        q.append(v)\n",
    "    \n",
    "    # Identifying pairs (i, j) that are independent\n",
    "    independent_pairs = []\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            # If i cannot reach j, AND j cannot reach i, they are independent.\n",
    "            if j not in reachable[i] and i not in reachable[j]:\n",
    "                independent_pairs.append((i, j))\n",
    "    \n",
    "    # Only loop through the independent pairs you found.\n",
    "    for i, j in independent_pairs:\n",
    "        for d_idx, device in enumerate(devices):\n",
    "            li = adjusted_node_latency[device][i]\n",
    "            lj = adjusted_node_latency[device][j]\n",
    "\n",
    "            # This binary variable decides the order ONLY for this independent pair.\n",
    "            b = solver.BoolVar(f\"order_{i}_{j}_on_{device}\")\n",
    "    \n",
    "            # This is the \"Big M\" formulation. It correctly activates the constraints \n",
    "            # only when BOTH nodes are on the SAME device.\n",
    "            EPS = 1e-6\n",
    "            \n",
    "            # Constraint 1: If i is before j (b=1)\n",
    "            # The term (3 - x_i - x_j - b) becomes 0 only if x_i=1, x_j=1, and b=1.\n",
    "            # Otherwise, the term is >= 1, making the constraint trivial.\n",
    "            solver.Add(s[i] + li + EPS <= s[j] + M * (3 - x[(i, d_idx)] - x[(j, d_idx)] - b))\n",
    "            \n",
    "            # Constraint 2: If j is before i (b=0)\n",
    "            # The term (2 - x_i - x_j + b) becomes 0 only if x_i=1, x_j=1, and b=0.\n",
    "            # Otherwise, the term is >= 1, making the constraint trivial.\n",
    "            solver.Add(s[j] + lj + EPS <= s[i] + M * (2 - x[(i, d_idx)] - x[(j, d_idx)] + b))\n",
    "\n",
    "    # Solve the problem\n",
    "    status = solver.Solve()\n",
    "\n",
    "    START_TIME = {}\n",
    "    END_TIME = {}\n",
    "    MAX_TIME = 0\n",
    "    \n",
    "    for i in range(len(nodes)):\n",
    "        completion_time = s[i].solution_value() + sum(x[(i, j)].solution_value() * adjusted_node_latency[devices[j]][i] for j in range(len(devices)))\n",
    "        START_TIME[i] = s[i].solution_value()\n",
    "        END_TIME[i] = completion_time\n",
    "        \n",
    "        if (completion_time > MAX_TIME):\n",
    "            MAX_TIME = completion_time\n",
    "    \n",
    "    print(f\"\\nNode processing MAX TIME:{MAX_TIME}:.3f\")    \n",
    "    \n",
    "    node_assignments = {}\n",
    "    x_list = []\n",
    "    \n",
    "    if status == solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "        print('Solution:')\n",
    "        \n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(devices)):\n",
    "                if x[(i, j)].solution_value() > 0:\n",
    "                    x_list.append((i, j))\n",
    "                    node_assignments[nodes[i]] = devices[j]\n",
    "                    print(f'Node {nodes[i]} assigned to {devices[j]}')\n",
    "        \n",
    "        print('Objective value =', objective.Value())\n",
    "\n",
    "        print(\"\\nPrecedence constraint sanity check:\")\n",
    "        for (parent, child) in edges:\n",
    "            for j, device_p in enumerate(devices):\n",
    "                for k, device_c in enumerate(devices):\n",
    "                    if x[(parent, j)].solution_value() == 1 and x[(child, k)].solution_value() == 1:\n",
    "                        start_p = s[parent].solution_value()\n",
    "                        start_c = s[child].solution_value()\n",
    "                        \n",
    "                        latency = adjusted_node_latency[device_p][parent]\n",
    "                        \n",
    "                        transfer = 0 if device_p == device_c else comm_latency[device_p][device_c][parent][child]\n",
    "                        expected_min_start = start_p + latency + transfer\n",
    "                        \n",
    "                        print(f\"\\nEdge {parent}  {child} across {devices[j]}  {devices[k]}\")\n",
    "                        print(f\"  s[{parent}] = {start_p:.3f}, s[{child}] = {start_c:.3f}, must be  {expected_min_start:.3f}\")\n",
    "                        \n",
    "                        assert start_c + 1e-4 >= expected_min_start, \"Constraint violated!\"\n",
    "\n",
    "        print(\"\\nNon-parallelism constraint sanity check:\")\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(i + 1, len(nodes)):\n",
    "                # Skip if there's a dependency in either direction\n",
    "                if j in reachable[i] or i in reachable[j]:\n",
    "                    continue\n",
    "        \n",
    "                for d_idx, device in enumerate(devices):\n",
    "                    if x[(i, d_idx)].solution_value() == 1 and x[(j, d_idx)].solution_value() == 1:\n",
    "                        s_i = s[i].solution_value()\n",
    "                        s_j = s[j].solution_value()\n",
    "                        li = adjusted_node_latency[device][i]\n",
    "                        lj = adjusted_node_latency[device][j]\n",
    "        \n",
    "                        finish_i = s_i + li\n",
    "                        finish_j = s_j + lj\n",
    "        \n",
    "                        overlap = not (finish_i <= s_j or finish_j <= s_i)\n",
    "        \n",
    "                        print(f\"\\nDevice {device}: Node {i} [{s_i:.3f}, {finish_i:.3f}) \"\n",
    "                              f\"vs Node {j} [{s_j:.3f}, {finish_j:.3f})\")\n",
    "                        \n",
    "                        if overlap:\n",
    "                            print(\"Overlap detected!\")\n",
    "                        else:\n",
    "                            print(\"No overlap  constraint respected\")\n",
    "        \n",
    "                        assert not overlap, f\"Nodes {i} and {j} overlap on device {device}\"\n",
    "        \n",
    "        node_energy_acc = {\n",
    "            \"D1\": [],\n",
    "            \"D2\": [],\n",
    "            \"D3\": [],\n",
    "            \"D4\": [],\n",
    "            \"D5\": [],\n",
    "            \"D6\": [],\n",
    "            \"D7\": []\n",
    "\n",
    "        }\n",
    "\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(devices)):\n",
    "                dynamic_energy = node_energy[devices[j]][i]\n",
    "                static_energy_per_node = (node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "                \n",
    "                node_energy_acc[devices[j]].append(dynamic_energy + static_energy_per_node)\n",
    "    \n",
    "        print(\"\\n=========================================================\\n\")\n",
    "        verify_solution(nodes, devices, node_energy, node_energy_acc, node_latency,\n",
    "                        node_flops, x, overall_latency_requirement, node_assignments, plot_summary, exp)\n",
    "        print(\"\\n=========================================================\\n\")\n",
    "        \n",
    "        return objective.Value(), MAX_TIME, START_TIME, END_TIME, [nodes, devices, node_energy, node_energy_acc, node_latency,\n",
    "                                                                   node_flops, x_list, overall_latency_requirement, node_assignments]\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "def heuristic1(model, nodes, devices, node_energy, node_flops, node_latency, overall_latency_requirement, device_capacity, device_utilization, static_energy):\n",
    "    energy = 0\n",
    "    time = 0\n",
    "\n",
    "    available_capacity = {device: device_capacity[device] * (1.0 - device_utilization[device]) for device in devices}\n",
    "\n",
    "    adjusted_node_latency = {}\n",
    "\n",
    "    for device in devices:\n",
    "        adjusted_node_latency[device] = [node_latency[device][i] / (1.0 - device_utilization[device]) for i in range(len(node_latency[device]))]\n",
    "\n",
    "    T_s = overall_latency_requirement / 1000\n",
    "        \n",
    "    edges = extract_dag_edges(model)\n",
    "    comm_latency = estimate_communication_latencies(devices, edges)\n",
    "\n",
    "    # Contains all the fixed dependencies for each node\n",
    "    dependencies = {i: [] for i in range(len(nodes))}\n",
    "    for item in edges:\n",
    "        if item[0] not in dependencies[item[1]]:\n",
    "            dependencies[item[1]].append(item[0])\n",
    "\n",
    "    # Containts the start of execution for each node\n",
    "    time_of_execution_start = {i: None for i in range(len(nodes))}\n",
    "    \n",
    "    # Containts the end of execution for each node\n",
    "    time_of_execution_end = {i: None for i in range(len(nodes))}\n",
    "\n",
    "    # Containts the earliest time a device is available\n",
    "    device_disponibility_time = {i: 0 for i in devices}\n",
    "\n",
    "    # Containts the updated dependencies\n",
    "    updated_depenencies = copy.deepcopy(dependencies)\n",
    "\n",
    "    # List of associations\n",
    "    association = {}\n",
    "    x_list = []\n",
    "    \n",
    "    while updated_depenencies:\n",
    "        # Get all nodes without dependencies in this iteration\n",
    "        nodes_with_zero = [k for k, v in updated_depenencies.items() if len(v) == 0]\n",
    "\n",
    "        # Iterate through this nodes, since they are available for allocation\n",
    "        for i in nodes_with_zero:\n",
    "            energy_list = []\n",
    "            device_energy = {}\n",
    "            \n",
    "            #For each device, get the amount of energy spent for the node i\n",
    "            for j, device in enumerate(devices):\n",
    "                dynamic_energy = node_energy[devices[j]][i] * (adjusted_node_latency[devices[j]][i] / node_latency[devices[j]][i])\n",
    "                static_energy_per_node = (adjusted_node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "                \n",
    "                total_energy = dynamic_energy + static_energy_per_node\n",
    "                energy_list.append((j, device, total_energy))\n",
    "                \n",
    "                device_energy[device] = total_energy\n",
    "\n",
    "            # Create a list of sorted devices, by the amount of energy spent\n",
    "            sorted_j = [j for _, j, _ in sorted(energy_list, key=lambda x: x[2])]\n",
    "            sorted_j_ind = [j for j, _, _ in sorted(energy_list, key=lambda x: x[2])]\n",
    "\n",
    "            chosen_device = sorted_j[0]\n",
    "            chosen_device_ind = sorted_j_ind[0]\n",
    "            max_inter_device_comm = 0\n",
    "            max_start_time_of_depenencies = 0\n",
    "            \n",
    "            # If exists dependencies (on the persisted/original dictionary)\n",
    "            if dependencies[i]:\n",
    "    \n",
    "                # Get the latest time of execution end among the dependencies\n",
    "                max_start_time_of_depenencies = max(time_of_execution_end[x] for x in dependencies[i])\n",
    "\n",
    "                # Find the longest communication delay from any parent of node i, if assigned to a different device\n",
    "                # Iterate over all parent nodes (dependencies) of node i\n",
    "                for dep in dependencies[i]:\n",
    "                     # Check if the parent node (dep) and the current node (i) are assigned to different devices\n",
    "                    if association[nodes[dep]] != chosen_device:\n",
    "                        # If they are on different devices, retrieve the communication latency between them\n",
    "                        inter_dev_time = comm_latency[association[nodes[dep]]][chosen_device][dep][i]\n",
    "                    else:\n",
    "                        # Otherwise, no communication delay is incurred\n",
    "                        inter_dev_time = 0\n",
    "                    \n",
    "                    # Update the maximum inter-device communication time if this one is greater\n",
    "                    if inter_dev_time > max_inter_device_comm:\n",
    "                        max_inter_device_comm = inter_dev_time\n",
    "\n",
    "            # Execution start of node i is the max between the device disponibity and the latest dependency\n",
    "            time_of_execution_start[i] = max(device_disponibility_time[chosen_device], max_start_time_of_depenencies) \n",
    "\n",
    "            # Execution end of node i is equal to the start time + the processing time + the inter device communication time\n",
    "            time_of_execution_end[i] = time_of_execution_start[i] + adjusted_node_latency[chosen_device][i] + max_inter_device_comm\n",
    "            \n",
    "            device_disponibility_time[chosen_device] = max(device_disponibility_time[chosen_device], time_of_execution_end[i])\n",
    "\n",
    "            print(\"Node: \", i, \" -- Device: \", chosen_device, \" -- Start: \", time_of_execution_start[i], \" -- End: \", time_of_execution_end[i], \"\\n\\n\")\n",
    "                \n",
    "            association[nodes[i]] = chosen_device\n",
    "            x_list.append((i, chosen_device_ind))\n",
    "            energy = energy + device_energy[chosen_device]\n",
    "            time = max(time, time_of_execution_end[i])\n",
    "            \n",
    "            del updated_depenencies[i]\n",
    "    \n",
    "            for child, dep in updated_depenencies.items():\n",
    "                if i in dep:\n",
    "                    updated_depenencies[child].remove(i)\n",
    "        \n",
    "    node_energy_acc = {\n",
    "        \"D1\": [],\n",
    "        \"D2\": [],\n",
    "        \"D3\": [],\n",
    "        \"D4\": [],\n",
    "        \"D5\": [],\n",
    "        \"D6\": [],\n",
    "        \"D7\": [],\n",
    "    }\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            dynamic_energy = node_energy[devices[j]][i]\n",
    "            static_energy_per_node = (node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "            \n",
    "            node_energy_acc[devices[j]].append(dynamic_energy + static_energy_per_node)\n",
    "\n",
    "    print(f\"ENERGY = {energy}:.3f\")\n",
    "    print(f\"TIME = {time}:.3f\")\n",
    "\n",
    "    return energy, time, time_of_execution_start, time_of_execution_end, [nodes, devices, node_energy, node_energy_acc, node_latency,\n",
    "                                                                          node_flops, x_list, overall_latency_requirement, association]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def heuristic2(model, nodes, devices, node_energy, node_flops, node_latency, overall_latency_requirement, device_capacity, device_utilization, static_energy):\n",
    "    energy = 0\n",
    "    time = 0\n",
    "\n",
    "    available_capacity = {device: device_capacity[device] * (1.0 - device_utilization[device]) for device in devices}\n",
    "\n",
    "    adjusted_node_latency = {}\n",
    "\n",
    "    for device in devices:\n",
    "        adjusted_node_latency[device] = [node_latency[device][i] / (1.0 - device_utilization[device]) for i in range(len(node_latency[device]))]\n",
    "\n",
    "    T_s = overall_latency_requirement / 1000\n",
    "        \n",
    "    edges = extract_dag_edges(model)\n",
    "    comm_latency = estimate_communication_latencies(devices, edges)\n",
    "\n",
    "    # Contains all the fixed dependencies for each node\n",
    "    dependencies = {i: [] for i in range(len(nodes))}\n",
    "    \n",
    "    for item in edges:\n",
    "        if item[0] not in dependencies[item[1]]:\n",
    "            dependencies[item[1]].append(item[0])\n",
    "\n",
    "    # Contains the start of execution for each node\n",
    "    time_of_execution_start = {i: None for i in range(len(nodes))}\n",
    "    \n",
    "    # Contains the end of execution for each node\n",
    "    time_of_execution_end = {i: None for i in range(len(nodes))}\n",
    "\n",
    "    # Contains the earliest time a device is available\n",
    "    device_disponibility_time = {i: 0 for i in devices}\n",
    "\n",
    "    # Containts the updated dependencies\n",
    "    updated_depenencies = copy.deepcopy(dependencies)\n",
    "\n",
    "    # List of associations\n",
    "    association = {}\n",
    "    x_list = []\n",
    "    \n",
    "    while updated_depenencies:\n",
    "        # Get all nodes without dependencies in this iteration\n",
    "        nodes_with_zero = [k for k, v in updated_depenencies.items() if len(v) == 0]\n",
    "\n",
    "        # Iterate through this nodes, since they are available for allocation\n",
    "        for i in nodes_with_zero:\n",
    "            energy_list = []\n",
    "            end_list = []\n",
    "            device_energy = {}\n",
    "            start_time_aux = {}\n",
    "            end_time_aux = {}\n",
    "            \n",
    "            #For each device we get the amount of energy spent for the node i\n",
    "            for j, device in enumerate(devices):\n",
    "                dynamic_energy = node_energy[devices[j]][i] * (adjusted_node_latency[devices[j]][i] / node_latency[devices[j]][i])\n",
    "                static_energy_per_node = (adjusted_node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "                \n",
    "                total_energy = dynamic_energy + static_energy_per_node\n",
    "                energy_list.append((device, total_energy))\n",
    "                \n",
    "                device_energy[device] = total_energy\n",
    "\n",
    "                max_inter_device_comm = 0\n",
    "                max_start_time_of_depenencies = 0\n",
    "                \n",
    "                # If exists dependencies (on the persisted/original dictionary)\n",
    "                if dependencies[i]:\n",
    "        \n",
    "                    # Get the latest time of execution end among the dependencies\n",
    "                    max_start_time_of_depenencies = max(time_of_execution_end[x] for x in dependencies[i])\n",
    "    \n",
    "                    # Find the longest communication delay from any parent of node i, if assigned to a different device\n",
    "                    # Iterate over all parent nodes (dependencies) of node i\n",
    "                    for dep in dependencies[i]:\n",
    "                        # Check if the parent node (dep) and the current node (i) are assigned to different devices\n",
    "                        if association[nodes[dep]] != chosen_device:\n",
    "                            # If they are on different devices, retrieve the communication latency between them\n",
    "                            inter_dev_time = comm_latency[association[nodes[dep]]][chosen_device][dep][i]\n",
    "                        else:\n",
    "                            # Otherwise, no communication delay is incurred\n",
    "                            inter_dev_time = 0\n",
    "                        \n",
    "                        # Update the maximum inter-device communication time if this one is greater\n",
    "                        if inter_dev_time > max_inter_device_comm:\n",
    "                            max_inter_device_comm = inter_dev_time\n",
    "\n",
    "                start_time_aux[device] = max(device_disponibility_time[device], max_start_time_of_depenencies) \n",
    "\n",
    "                end_list.append((j, device, start_time_aux[device] + adjusted_node_latency[device][i] + max_inter_device_comm))\n",
    "                end_time_aux[device] = start_time_aux[device] + adjusted_node_latency[device][i] + max_inter_device_comm\n",
    "\n",
    "\n",
    "            # Create a list of sorted devices, by the amount of energy spent\n",
    "            sorted_j = [j for _, j, _ in sorted(end_list, key=lambda x: x[2])]\n",
    "            sorted_j_ind = [j for j, _, _ in sorted(end_list, key=lambda x: x[2])]\n",
    "\n",
    "            chosen_device = sorted_j[0]\n",
    "            chosen_device_ind = sorted_j_ind[0]\n",
    "\n",
    "            # Execution start of node i is the max between the device disponibity and the latest dependency\n",
    "            time_of_execution_start[i] = start_time_aux[chosen_device] \n",
    "\n",
    "            # Execution end of node i is equal to the start time + the processing time + the inter device communication delay\n",
    "            time_of_execution_end[i] = end_time_aux[chosen_device]\n",
    "            \n",
    "            device_disponibility_time[chosen_device] = max(device_disponibility_time[chosen_device], time_of_execution_end[i])\n",
    "\n",
    "            print(\"Node: \", i, \" -- Device: \", chosen_device, \" -- Start: \", time_of_execution_start[i], \" -- End: \", time_of_execution_end[i], \"\\n\\n\")\n",
    "                \n",
    "            association[nodes[i]] = chosen_device\n",
    "            x_list.append((i, chosen_device_ind))\n",
    "            energy = energy + device_energy[chosen_device]\n",
    "            time = max(time, time_of_execution_end[i])\n",
    "            \n",
    "            del updated_depenencies[i]\n",
    "    \n",
    "            for child, dep in updated_depenencies.items():\n",
    "                if i in dep:\n",
    "                    updated_depenencies[child].remove(i)\n",
    "\n",
    "    node_energy_acc = {\n",
    "        \"D1\": [],\n",
    "        \"D2\": [],\n",
    "        \"D3\": [],\n",
    "        \"D4\": [],\n",
    "        \"D5\": [],\n",
    "        \"D6\": [],\n",
    "        \"D7\": [],\n",
    "    }\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(devices)):\n",
    "            dynamic_energy = node_energy[devices[j]][i]\n",
    "            static_energy_per_node = (node_latency[devices[j]][i] / 1000) * static_energy[devices[j]]\n",
    "            \n",
    "            node_energy_acc[devices[j]].append(dynamic_energy + static_energy_per_node)\n",
    "\n",
    "    print(f\"ENERGY = {energy}:.3f\")\n",
    "    print(f\"TIME = {time}:.3f\")\n",
    "    \n",
    "    return energy, time, time_of_execution_start, time_of_execution_end, [nodes, devices, node_energy, node_energy_acc, node_latency,\n",
    "                                                                          node_flops, x_list, overall_latency_requirement, association]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device_capabilities = {\n",
    "    'D1': D1_GFLOPS,\n",
    "    'D2': D2_GFLOPS,\n",
    "    'D3': D3_GFLOPS,\n",
    "    'D4': D4_GFLOPS,\n",
    "    'D5': D5_GFLOPS,\n",
    "    'D6': D6_GFLOPS,\n",
    "    'D7': D7_GFLOPS\n",
    "}\n",
    "\n",
    "device_efficiency = {\n",
    "    'D1': D1_EFFICIENCY,\n",
    "    'D2': D2_EFFICIENCY,\n",
    "    'D3': D3_EFFICIENCY,\n",
    "    'D4': D4_EFFICIENCY,\n",
    "    'D5': D5_EFFICIENCY,\n",
    "    'D6': D6_EFFICIENCY,\n",
    "    'D7': D7_EFFICIENCY\n",
    "}\n",
    "\n",
    "static_energy = {\n",
    "    'D1': D1_STATIC_POWER,\n",
    "    'D2': D2_STATIC_POWER,\n",
    "    'D3': D3_STATIC_POWER,\n",
    "    'D4': D4_STATIC_POWER,\n",
    "    'D5': D5_STATIC_POWER,\n",
    "    'D6': D6_STATIC_POWER,\n",
    "    'D7': D7_STATIC_POWER\n",
    "}\n",
    "\n",
    "device_utilization = {\n",
    "    'D1': 0.7,\n",
    "    'D2': 0.7,\n",
    "    'D3': 0.7,\n",
    "    'D4': 0.0,\n",
    "    'D5': 0.0,\n",
    "    'D6': 0.0,\n",
    "    'D7': 0.0\n",
    "}\n",
    "\n",
    "computing_time = DAG_PROFILE['computing_time']\n",
    "energy_cost = DAG_PROFILE['energy_cost']\n",
    "\n",
    "nodes = []\n",
    "\n",
    "for node in node_flops:\n",
    "    nodes.append(node)\n",
    "\n",
    "overall_latency_requirement = 20\n",
    "\n",
    "devices = [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Solving and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "F1_opt_obj, F1_MAX_TIME, F1_START_TIME, F1_END_TIME, F1_sol = graph_partition_S1(model, nodes, \n",
    "                                            devices, energy_cost, node_flops, computing_time,\n",
    "                                            overall_latency_requirement, device_capabilities, device_utilization, \n",
    "                                            static_energy, plot_summary=True, exp=5)\n",
    "end = time.time()\n",
    "F1_exe_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "F2_opt_obj, F2_MAX_TIME, F2_START_TIME, F2_END_TIME, F2_sol = graph_partition_S2(model, nodes, \n",
    "                                                devices, energy_cost, node_flops, computing_time,\n",
    "                                                overall_latency_requirement, device_capabilities, device_utilization, \n",
    "                                                static_energy, F1_opt_obj, plot_summary=True, exp=5)\n",
    "end = time.time()\n",
    "F2_exe_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "HE1_opt_obj, HE1_MAX_TIME, HE1_START_TIME, HE1_END_TIME, HE1_sol = heuristic1(model, nodes, devices, energy_cost, node_flops, computing_time,\n",
    "                overall_latency_requirement, device_capabilities, device_utilization, static_energy)\n",
    "end = time.time()\n",
    "HE1_exe_time = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "HE2_opt_obj, HE2_MAX_TIME, HE2_START_TIME, HE2_END_TIME, HE2_sol = heuristic2(model, nodes, devices, energy_cost, node_flops, computing_time,\n",
    "            overall_latency_requirement, device_capabilities, device_utilization, static_energy)\n",
    "end = time.time()\n",
    "HE2_exe_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Figure Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Uncomment to export results to a .pkl file\n",
    "'''\n",
    "Solution_Yolo = {}\n",
    "Solution_Yolo['F1'] = [F1_opt_obj, F1_MAX_TIME, F1_START_TIME, F1_END_TIME, F1_sol, F1_exe_time]\n",
    "Solution_Yolo['F2'] = [F2_opt_obj, F2_MAX_TIME, F2_START_TIME, F2_END_TIME, F2_sol, F2_exe_time]\n",
    "Solution_Yolo['H1'] = [HE1_opt_obj, HE1_MAX_TIME, HE1_START_TIME, HE1_END_TIME, HE1_sol, HE1_exe_time]\n",
    "Solution_Yolo['H2'] = [HE2_opt_obj, HE2_MAX_TIME, HE2_START_TIME, HE2_END_TIME, HE2_sol, HE2_exe_time]\n",
    "\n",
    "dl_model = yolo11n\n",
    "\n",
    "# Save to file\n",
    "with open(dl_model + \"_solution.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Solution_Yolo, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Uncomment to import results from a .pkl file\n",
    "'''\n",
    "dl_model = yolo11n\n",
    "\n",
    "# Load from file\n",
    "with open(dl_model + \"_solution.pkl\", \"rb\") as f:\n",
    "    Solution_Yolo = pickle.load(f)\n",
    "\n",
    "[F1_opt_obj, F1_MAX_TIME, F1_START_TIME, F1_END_TIME, F1_sol, F1_exe_time] = Solution_Yolo['F1']\n",
    "[F2_opt_obj, F2_MAX_TIME, F2_START_TIME, F2_END_TIME, F2_sol, F2_exe_time] = Solution_Yolo['F2']\n",
    "[HE1_opt_obj, HE1_MAX_TIME, HE1_START_TIME, HE1_END_TIME, HE1_sol, HE1_exe_time] = Solution_Yolo['H1']\n",
    "[HE2_opt_obj, HE2_MAX_TIME, HE2_START_TIME, HE2_END_TIME, HE2_sol, HE2_exe_time]  = Solution_Yolo['H2']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "def format_data(SOLUTION):\n",
    "    # Initialize dictionaries to store counts and summaries\n",
    "    device_node_count = {device: 0 for device in SOLUTION[1]}\n",
    "    flops_per_device = {device: 0 for device in SOLUTION[1]}\n",
    "    total_latency = {device: 0 for device in SOLUTION[1]}\n",
    "    total_energy = {device: 0 for device in SOLUTION[1]}\n",
    "    total_acc_energy = {device: 0 for device in SOLUTION[1]}\n",
    "\n",
    "    # Calculate and summarize information\n",
    "    for i, node in enumerate(SOLUTION[0]):\n",
    "        assigned_device = SOLUTION[8][node]\n",
    "        device_node_count[assigned_device] += 1\n",
    "\n",
    "        for j, device in enumerate(SOLUTION[1]):\n",
    "            if (i, j) in SOLUTION[6]:\n",
    "                total_latency[device] += SOLUTION[4][device][i]\n",
    "                total_energy[device] += SOLUTION[2][device][i]\n",
    "                total_acc_energy[device] += SOLUTION[3][device][i]\n",
    "    \n",
    "    for node, device in SOLUTION[8].items():\n",
    "        if node in SOLUTION[5]: \n",
    "\n",
    "            flops_per_device[device] += SOLUTION[5][node]\n",
    "\n",
    "    # Check latency requirements\n",
    "    meets_latency_requirements = all(latency <= SOLUTION[7] for latency in total_latency.values())\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Meets Latency Requirements:\", meets_latency_requirements)\n",
    "\n",
    "    print(\"\\nSolution Verification Summary:\\n\")\n",
    "    for device in SOLUTION[1]:\n",
    "        print(f\" Device: {device}\")\n",
    "        print(f\" Number of Nodes Assigned: {device_node_count[device]}\")\n",
    "        print(f\" GFLOPs computed: {flops_per_device[device]:.4f}\")\n",
    "        print(f\" Total computing time: {total_latency[device]:.4f} ms\")\n",
    "        print(f\" Total energy cost: {total_energy[device]:.4f} J\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    #print(\"\\nTotal Latency: {0:.4f} milliseconds\".format(sum(total_latency.values())))\n",
    "    print(\"Total Energy: {0:.4f} J\".format(sum(total_energy.values())))\n",
    "\n",
    "    flops_per_device[\"Total\"] = sum(flops_per_device.values())\n",
    "    total_latency[\"Total\"] = sum(total_latency.values())\n",
    "    total_acc_energy[\"Total\"] = sum(total_acc_energy.values())\n",
    "\n",
    "    device_node_count[\"Total\"] = sum(device_node_count.values())\n",
    "    \n",
    "    return flops_per_device, total_latency, total_acc_energy, device_node_count\n",
    "\n",
    "\n",
    "def result_analysis(F1, F2, H1, H2, F1_COMP_TIME, F2_COMP_TIME, H1_COMP_TIME, H2_COMP_TIME, F1_EXEC_TIME, F2_EXEC_TIME, H1_EXEC_TIME, H2_EXEC_TIME):\n",
    "    F2_flops_per_device, F2_total_latency, F2_total_acc_energy, F2_device_node_count = format_data(F2)\n",
    "    F1_flops_per_device, F1_total_latency, F1_total_acc_energy, F1_device_node_count = format_data(F1)\n",
    "    H1_flops_per_device, H1_total_latency, H1_total_acc_energy, H1_device_node_count = format_data(H1)\n",
    "    H2_flops_per_device, H2_total_latency, H2_total_acc_energy, H2_device_node_count = format_data(H2)\n",
    "\n",
    "    plot_results(F1_flops_per_device, F2_flops_per_device, H1_flops_per_device, H2_flops_per_device, \"GFLOPs computed per device\", \"Devices\", \"GFLOPs\", F1, \"1\")\n",
    "    plot_results(F1_total_latency, F2_total_latency, H1_total_latency, H2_total_latency, \"Total computing time per device\", \"Devices\", \"Computing time (ms)\", F1, \"2\")\n",
    "    plot_results(F1_total_acc_energy, F2_total_acc_energy, H1_total_acc_energy, H2_total_acc_energy, \"Total computing energy per device\", \"Devices\", \"Energy (J)\", F1, \"3\") \n",
    "    plot_results(F1_device_node_count, F2_device_node_count, H1_device_node_count, H2_device_node_count, \"Total device node count\", \"Devices\", \"Number of nodes\", F1, \"4\")\n",
    "\n",
    "    completion_time_comparison(F1_COMP_TIME, F2_COMP_TIME, H1_COMP_TIME, H2_COMP_TIME)\n",
    "    execution_time_comparison(F1_EXEC_TIME, F2_EXEC_TIME, H1_EXEC_TIME, H2_EXEC_TIME)\n",
    "\n",
    "\n",
    "def plot_results(F1_data, F2_data, H1_data, H2_data, title, xlabel, ylabel, F1, plot_ind):\n",
    "    DEVICES_NAME = {\"D1\": \"NV-L40\",\n",
    "                    \"D2\": \"NV-T4\",\n",
    "                    \"D3\": \"NV-A30\",\n",
    "                    \"D4\": \"AL-U2\",\n",
    "                    \"D5\": \"AL-U1\",\n",
    "                    \"D6\": \"BL3\",\n",
    "                    \"D7\": \"BL2\"}\n",
    "    \n",
    "    labels = [DEVICES_NAME[x] if x != \"Total\" else \"TOTAL\" for x in F1_data.keys()]\n",
    "\n",
    "    x_labels = np.arange(len(labels))\n",
    "\n",
    "    F1_data = list(F1_data.values())\n",
    "    F2_data = list(F2_data.values())\n",
    "    H1_data = list(H1_data.values())\n",
    "    H2_data = list(H2_data.values())\n",
    "\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.rcParams[\"font.family\"] = \"Ubuntu\"\n",
    "    plt.xticks(x_labels, labels, rotation=30)\n",
    "\n",
    "    F1_rects = plt.bar(x_labels-0.30, F1_data, 0.2, color=\"#b0d4ec\", edgecolor='black', label='1-stage', hatch=\"/\")\n",
    "    F2_rects = plt.bar(x_labels-0.10, F2_data, 0.2, color='#006bb3', edgecolor='black', label='2-stage', hatch=\"\\\\\")\n",
    "    H1_rects = plt.bar(x_labels+0.10, H1_data, 0.2, color='#c0b1ec', edgecolor='black', label='heu_es', hatch=\"-\")\n",
    "    H2_rects = plt.bar(x_labels+0.30, H2_data, 0.2, color='#ecb1dd', edgecolor='black', label='heu_ct', hatch=\"|||||\")\n",
    "\n",
    "    plt.xlabel(xlabel) \n",
    "    plt.ylabel(ylabel) \n",
    "    plt.grid(axis = 'y', linestyle='--', linewidth=0.6)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylim(0, max(F1_data)+(0.4*max(F1_data)))\n",
    "    plt.savefig(\"figs/\" + plot_ind + \".pdf\", dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.savefig(\"figs/PNG/\" + plot_ind + \".png\", dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "def completion_time_comparison(F1_COMP_TIME, F2_COMP_TIME, H1_COMP_TIME, H2_COMP_TIME): \n",
    "    F1_MAX_TIME = [round(x, 3) for x in F1_COMP_TIME]\n",
    "    F2_MAX_TIME = [round(x, 3) for x in F2_COMP_TIME]\n",
    "    H1_MAX_TIME = [round(x, 3) for x in H1_COMP_TIME]\n",
    "    H2_MAX_TIME = [round(x, 3) for x in H2_COMP_TIME]\n",
    "\n",
    "    x_labels = np.arange(len(F1_MAX_TIME))\n",
    "\n",
    "    plt.figure(figsize=(4,1.2))\n",
    "    plt.rcParams[\"font.family\"] = \"Ubuntu\"\n",
    "\n",
    "    F1_rects = plt.bar(x_labels-0.60, F1_MAX_TIME, 0.40, color = \"#b0d4ec\", edgecolor='black', label='1-stage', hatch=\"/\")\n",
    "    F2_rects = plt.bar(x_labels-0.20, F2_MAX_TIME, 0.40, color = '#006bb3', edgecolor='black', label='2-stage', hatch=\"\\\\\")\n",
    "    H1_rects = plt.bar(x_labels+0.20, H1_MAX_TIME, 0.40, color = '#c0b1ec', edgecolor='black', label='heu_es', hatch=\"-\")\n",
    "    H2_rects = plt.bar(x_labels+0.60, H2_MAX_TIME, 0.40, color = '#ecb1dd', edgecolor='black', label='heu_ct', hatch=\"|\")\n",
    "    \n",
    "    plt.bar_label(F1_rects, fontsize=10, padding=3)\n",
    "    plt.bar_label(F2_rects, fontsize=10, padding=3)\n",
    "    plt.bar_label(H1_rects, fontsize=10, padding=3)\n",
    "    plt.bar_label(H2_rects, fontsize=10, padding=3)\n",
    "\n",
    "    plt.ylabel(\"Completion time (ms)      \")\n",
    "    plt.xticks([-0.6, -0.2, +0.2, +0.6], [\"1-stage\", \"2-stage\", \"heu_es\", \"heu_ct\"])\n",
    "    plt.grid(axis = 'y', linestyle='--', linewidth=0.6)\n",
    "\n",
    "    plt.ylim(0, max(F1_MAX_TIME[0], F2_MAX_TIME[0])+(0.25*max(F1_MAX_TIME[0], F2_MAX_TIME[0])))\n",
    "    plt.savefig(\"figs/5.pdf\", dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.savefig(\"figs/PNG/5.png\", dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "def execution_time_comparison(F1_EXEC_TIME, F2_EXEC_TIME, H1_EXEC_TIME, H2_EXEC_TIME): \n",
    "    F1_MAX_TIME = [round(x, 3) for x in F1_EXEC_TIME]\n",
    "    F2_MAX_TIME = [round(x, 3) for x in F2_EXEC_TIME]\n",
    "    H1_MAX_TIME = [round(x, 3) for x in H1_EXEC_TIME]\n",
    "    H2_MAX_TIME = [round(x, 3) for x in H2_EXEC_TIME]\n",
    "    \n",
    "    x_labels = np.arange(len(F1_MAX_TIME))\n",
    "\n",
    "    plt.figure(figsize=(4,1.2))\n",
    "    plt.rcParams[\"font.family\"] = \"Ubuntu\"\n",
    "\n",
    "    F1_rects = plt.bar(x_labels-0.60, F1_MAX_TIME, 0.40, color = \"#b0d4ec\", edgecolor='black', label='stage 1', hatch=\"/\")\n",
    "    F2_rects = plt.bar(x_labels-0.20, F2_MAX_TIME, 0.40, color = '#006bb3', edgecolor='black', label='stage 2', hatch=\"\\\\\")\n",
    "    H1_rects = plt.bar(x_labels+0.20, H1_MAX_TIME, 0.40, color = '#c0b1ec', edgecolor='black', label='heu_es', hatch=\"-\")\n",
    "    H2_rects = plt.bar(x_labels+0.60, H2_MAX_TIME, 0.40, color = '#ecb1dd', edgecolor='black', label='heu_ct', hatch=\"|\")\n",
    "    \n",
    "    plt.bar_label(F1_rects, fontsize=10, padding=3)\n",
    "    plt.bar_label(F2_rects, fontsize=10, padding=3)\n",
    "    plt.bar_label(H1_rects, fontsize=10, padding=3)\n",
    "    plt.bar_label(H2_rects, fontsize=10, padding=3)\n",
    "    \n",
    "    plt.ylabel(\"Execution time (s)         \")\n",
    "    plt.xticks([-0.6, -0.2, +0.2, +0.6], [\"stage 1\", \"stage 2\", \"heu_es\", \"heu_ct\"])\n",
    "    plt.grid(axis = 'y', linestyle='--', linewidth=0.6)\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(0, max(F1_MAX_TIME[0], F2_MAX_TIME[0])+(40*max(F1_MAX_TIME[0], F2_MAX_TIME[0])))\n",
    "    plt.savefig(\"figs/6.pdf\", dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.savefig(\"figs/PNG/6.png\", dpi=600, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "result_analysis(F1_sol, F2_sol, HE1_sol, HE2_sol, [F1_MAX_TIME], [F2_MAX_TIME], [HE1_MAX_TIME], [HE2_MAX_TIME],\n",
    "               [F1_exe_time], [F2_exe_time], [HE1_exe_time], [HE2_exe_time])\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
